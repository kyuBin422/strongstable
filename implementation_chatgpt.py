"""
SRTI-strong: Phase 1 and Phase 2 implementation (Python)

This module implements Phase 1 and Phase 2 of the SRTI-strong algorithm
(as described in the user's algorithm text). It focuses on manipulating
preference lists with ties and performing the deletions / semi-assignments
required for Phase 1, and the branching procedure of Phase 2.

Assumptions & representations:
- Agents are represented by hashable values (ints or strings).
- Preferences with ties are represented as a list of "tie groups".
  Example:
    prefs[p] = [ ['a','b'], ['c'], ['d','e','f'] ]
  Here {'a','b'} is the head tie group f(p), and {'d','e','f'} is the tail tie group l(p).
- The head f(p) is always the first non-empty tie-group in prefs[p].
  The tail l(p) is always the last non-empty tie-group in prefs[p].
- When we "delete a pair {p,q}" we remove q from p's preference structure and vice versa.
  If a tie-group becomes empty it is removed from the list of tie-groups.
- For the "critical set" computation we:
  1. Construct the bipartite semi-assignment graph U (proposers) -> V (receivers) with edges
     from x in U to each y in f(x).
  2. Compute a maximum matching (Hopcroft-Karp).
  3. Starting from unmatched U nodes, explore alternating paths (free-edge then matched-edge),
     collecting reachable U nodes R_U. We set critical Z = U \ R_U.
  This choice follows the standard alternating-path based decomposition used in
  bipartite matching / Dulmage–Mendelsohn style analysis and matches the
  "unique minimal set of proposing nodes with maximum deficiency" in practice.
  (If you need a different formalization of the "critical set", please state it.)

Notes:
- The final perfect matching in Phase 2 requires a general-graph matching (Blossom).
  This code will attempt to use networkx's max_weight_matching (which implements Blossom).
  If networkx is not available, the function will raise a descriptive error.
- The code is defensive: checks input types and common consistency errors.
- The implementation favors clarity and correctness over micro-optimizations.

Author: Generated by ChatGPT (role: algorithm-to-python converter)
"""

from collections import deque, defaultdict
from copy import deepcopy
from typing import Dict, List, Hashable, Set, Tuple, Optional


# ---------------------------
# Utility helpers for prefs
# ---------------------------

def normalize_preferences(raw_prefs: Dict[Hashable, List[List[Hashable]]]) -> Dict[Hashable, List[List[Hashable]]]:
    """
    Validate and normalize the preference structure.
    Ensures each agent's preference is a list of non-empty tie-groups (lists).
    """
    if not isinstance(raw_prefs, dict):
        raise TypeError("Preferences must be a dict: agent -> list of tie-groups (lists).")
    prefs = {}
    for agent, tie_groups in raw_prefs.items():
        if tie_groups is None:
            prefs[agent] = []
            continue
        if not isinstance(tie_groups, list):
            raise TypeError(f"Preferences for {agent} must be a list of tie-groups.")
        cleaned = []
        for group in tie_groups:
            if not isinstance(group, (list, set, tuple)):
                raise TypeError(f"Each tie-group must be a list/set/tuple for agent {agent}.")
            group_list = [g for g in group]
            if len(group_list) > 0:
                cleaned.append(group_list)
        prefs[agent] = cleaned
    return prefs


def head_of(prefs: Dict[Hashable, List[List[Hashable]]], agent: Hashable) -> List[Hashable]:
    """Return head tie-group f(agent) (empty list if no preferences)."""
    groups = prefs.get(agent, [])
    return groups[0][:] if groups else []


def tail_of(prefs: Dict[Hashable, List[List[Hashable]]], agent: Hashable) -> List[Hashable]:
    """Return tail tie-group l(agent) (empty list if no preferences)."""
    groups = prefs.get(agent, [])
    return groups[-1][:] if groups else []


def remove_pair(prefs: Dict[Hashable, List[List[Hashable]]], a: Hashable, b: Hashable) -> None:
    """
    Delete pair {a,b} from preferences: remove b from a's tie-groups and a from b's tie-groups.
    Removes empty tie-groups.
    """
    for x, y in ((a, b), (b, a)):
        if x not in prefs:
            continue
        new_groups = []
        changed = False
        for group in prefs[x]:
            new_group = [item for item in group if item != y]
            if new_group:
                new_groups.append(new_group)
            else:
                changed = True
        prefs[x] = new_groups


def prefers(preference: Dict[Hashable, List[List[Hashable]]], receiver: Hashable, a: Hashable, b: Hashable) -> bool:
    """
    Return True if 'receiver' strictly prefers 'a' to 'b' according to their tie-structured preferences.
    If a and b are in same tie-group or one is missing, it's not "prefers".
    """
    groups = preference.get(receiver, [])
    pos = {}
    for idx, group in enumerate(groups):
        for agent in group:
            pos[agent] = idx
    if a not in pos or b not in pos:
        # If receiver doesn't list either, cannot strictly prefer
        return False
    return pos[a] < pos[b]


# ---------------------------
# Hopcroft-Karp (bipartite matching)
# ---------------------------

def hopcroft_karp_bipartite_matching(
        U_nodes: List[Hashable],
        V_nodes: List[Hashable],
        edges: Dict[Hashable, List[Hashable]]
) -> Dict[Hashable, Hashable]:
    """
    Hopcroft-Karp algorithm for maximum bipartite matching.
    U_nodes: list of nodes on U side (proposers).
    V_nodes: list of nodes on V side (receivers).
    edges: dict u -> list of v neighbors (only for u in U_nodes)
    Returns a dict match_u where keys are U-nodes matched to a V-node (match_u[u] = v).
    Note: To check matched pairs from V side, invert the mapping.
    """
    # Internal consistent sets
    U = list(U_nodes)
    V = list(V_nodes)
    U_index = {u: i for i, u in enumerate(U)}
    V_index = {v: i for i, v in enumerate(V)}

    # adjacency lists for U (using indices for speed)
    adj = [[] for _ in U]
    for u in U:
        for v in edges.get(u, []):
            if v in V_index:
                adj[U_index[u]].append(V_index[v])

    # matchings by indices: pair_u[u_idx] = v_idx or -1
    pair_u = [-1] * len(U)
    pair_v = [-1] * len(V)
    INF = 10 ** 9

    from collections import deque

    def bfs():
        dist = [-1] * len(U)
        q = deque()
        for u_idx in range(len(U)):
            if pair_u[u_idx] == -1:
                dist[u_idx] = 0
                q.append(u_idx)
        found_free = False
        while q:
            u_idx = q.popleft()
            for v_idx in adj[u_idx]:
                pu = pair_v[v_idx]
                if pu != -1 and dist[pu] == -1:
                    dist[pu] = dist[u_idx] + 1
                    q.append(pu)
                if pu == -1:
                    found_free = True
        return dist, found_free

    def dfs(u_idx, dist):
        for v_idx in adj[u_idx]:
            pu = pair_v[v_idx]
            if pu == -1 or (dist[pu] == dist[u_idx] + 1 and dfs(pu, dist)):
                pair_u[u_idx] = v_idx
                pair_v[v_idx] = u_idx
                return True
        dist[u_idx] = -1
        return False

    # Main loop
    while True:
        dist, found = bfs()
        if not found:
            break
        for u_idx in range(len(U)):
            if pair_u[u_idx] == -1:
                dfs(u_idx, dist)

    # Build mapping from U to V for output
    result = {}
    for u_idx, v_idx in enumerate(pair_u):
        if v_idx != -1:
            result[U[u_idx]] = V[v_idx]
    return result


# ---------------------------
# Alternating-path reachability (for critical set)
# ---------------------------

def compute_critical_set(
        prefs: Dict[Hashable, List[List[Hashable]]],
) -> Set[Hashable]:
    """
    Given current preferences, form the semi-assignment bipartite graph U->V where
    U and V both contain every agent with a non-empty list, and edges are from x in U to y in f(x).
    Compute maximum matching using Hopcroft-Karp, then compute alternating-path reachable
    U nodes starting from unmatched U-nodes. Return critical set Z = U \ reachable_U.
    """
    # Agents with non-empty lists
    agents = [a for a, groups in prefs.items() if groups]
    U = agents[:]  # proposers
    V = agents[:]  # receivers (separate node copies conceptually)

    # Build edges U -> V for each y in f(x)
    edges = {}
    for x in U:
        head = head_of(prefs, x)
        edges[x] = [y for y in head if y in V]

    # Compute maximum bipartite matching
    matching = hopcroft_karp_bipartite_matching(U, V, edges)  # dict u->v

    # Build reverse mapping for matched edges
    matched_v_to_u = {v: u for u, v in matching.items()}

    # BFS/DFS alternating paths from unmatched U nodes:
    reachable_u: Set[Hashable] = set()
    reachable_v: Set[Hashable] = set()
    queue = deque()
    # Unmatched U nodes start
    for u in U:
        if u not in matching:
            queue.append(('U', u))
            reachable_u.add(u)

    # Build quick lookup of adjacency sets
    adj_u = {u: set(edges.get(u, [])) for u in U}
    adj_v = defaultdict(set)
    for u, vs in edges.items():
        for v in vs:
            adj_v[v].add(u)

    while queue:
        side, node = queue.popleft()
        if side == 'U':
            # traverse free edges U->V not in matching (i.e., all edges from U to neighbors)
            for v in adj_u.get(node, []):
                if v not in reachable_v:
                    reachable_v.add(v)
                    # if v is matched to some u2, we can traverse matched edge v->u2
                    if v in matched_v_to_u:
                        u2 = matched_v_to_u[v]
                        if u2 not in reachable_u:
                            reachable_u.add(u2)
                            queue.append(('U', u2))
        # (we only push 'U' nodes because V->U matched-edge expansions are handled above)

    # Critical set Z is U \ reachable_u
    Z = set(U) - reachable_u
    return Z


# ---------------------------
# Phase 1 implementation
# ---------------------------

def phase1_table(prefs: Dict[Hashable, List[List[Hashable]]]) -> Tuple[Dict[Hashable, List[List[Hashable]]], bool]:
    """
    Perform Phase 1 main loop on a copy of preferences and return the resulting table (prefs after deletions).
    Also returns a boolean flag 'infeasible_odd' indicating if an odd number of agents
    with non-empty lists remain at termination (in which case no strongly stable matching exists).
    """
    prefs = normalize_preferences(prefs)
    # semi-assignment structures:
    semi_assigned_to: Dict[Hashable, Set[Hashable]] = defaultdict(
        set)  # proposer p -> set of receivers it's semi-assigned to
    semi_assigned_from: Dict[Hashable, Set[Hashable]] = defaultdict(
        set)  # receiver q -> set of proposers semi-assigned to q

    # Helper to check if an agent is free: free if not semi-assigned to anyone and has a non-empty list
    def is_free(agent):
        return (not semi_assigned_to.get(agent)) and bool(prefs.get(agent))

    # Main repeat-until loop
    while True:
        # Iterative step: while some agent p is free and has non-empty preference list
        progress = True
        while True:
            any_action = False
            for p in list(prefs.keys()):
                if is_free(p):
                    head = head_of(prefs, p)
                    if not head:
                        continue
                    # p becomes semi-assigned to all q in f(p)
                    for q in head:
                        if q not in semi_assigned_from or p not in semi_assigned_from[q]:
                            semi_assigned_to[p].add(q)
                            semi_assigned_from[q].add(p)
                            any_action = True
                        # For each r such that q prefers p to r
                        # We need to find all r in q's preference list strictly worse than p
                        # Iterate over all agents r in q's prefs (flatten)
                        q_groups = prefs.get(q, [])
                        # Build ordering index
                        q_pos = {}
                        for idx, group in enumerate(q_groups):
                            for ag in group:
                                q_pos[ag] = idx
                        if p not in q_pos:
                            continue  # q doesn't list p, nothing to do
                        # find all r with q_pos[r] > q_pos[p]
                        worse_rs = [r for r, pos in q_pos.items() if pos > q_pos[p]]
                        for r in worse_rs:
                            if r in semi_assigned_to and q in semi_assigned_to[r]:
                                # break the semi-assignment r -> q
                                semi_assigned_to[r].discard(q)
                                semi_assigned_from[q].discard(r)
                                # delete pair {q, r}
                                remove_pair(prefs, q, r)
                                any_action = True
            if not any_action:
                break

        # Form semi-assignment graph and find critical set Z
        Z = compute_critical_set(prefs)
        if not Z:
            break  # until Z == empty set

        # For each agent p in N(Z) (neighborhood of Z in V side),
        # delete all pairs {p, q} where q in tail(p)
        # First calculate N(Z): nodes adjacent to at least one member of Z in semi-graph
        # semi-graph edges from x in U to y in f(x). So N(Z) are receivers y in f(x) for some x in Z.
        neighborhood = set()
        for x in Z:
            head = head_of(prefs, x)
            for y in head:
                neighborhood.add(y)
        # For each p in neighborhood, delete pairs {p, q} for q in tail(p)
        for p in list(neighborhood):
            tail = tail_of(prefs, p)
            for q in list(tail):
                remove_pair(prefs, p, q)
        # Having deleted pairs, we must break any semi-assignments involving deleted pairs
        # Rebuild semi-assignments from scratch: clear and recompute from current free agents in next iteration.
        semi_assigned_to.clear()
        semi_assigned_from.clear()
        # The outer loop continues until Z empty
    # On termination of iterative step, check odd number of agents with non-empty lists
    non_empty_agents = [a for a, groups in prefs.items() if groups]
    infeasible_odd = (len(non_empty_agents) % 2 == 1)
    return prefs, infeasible_odd


# ---------------------------
# Phase 2 implementation
# ---------------------------

def phase2_solve(initial_prefs: Dict[Hashable, List[List[Hashable]]]) -> Tuple[
    Optional[Dict[Hashable, Hashable]], Dict[Hashable, List[List[Hashable]]]]:
    """
    Execute Phase 2 on the initial table T^1 (which should be the output of Phase 1).
    Returns:
      - A strongly stable matching as dict agent -> matched_agent if found (perfect matching),
        or None if no strongly stable matching exists (or missing final matching due to missing library).
      - The final preference table after Phase 2 termination (or the table at point of failure).
    Notes:
      - This function will attempt to compute the final perfect matching in the final assignment graph
        using networkx's max_weight_matching (Edmonds' algorithm / Blossom). If networkx is not present,
        the function will raise a RuntimeError with instructions to install it.
    """
    # Work on copies
    T, infeasible_odd = phase1_table(initial_prefs)
    if infeasible_odd:
        # early exit: no strongly stable matching exists
        return None, T

    # Helper: check if some agent x has f_T(x) != l_T(x)
    def first_agent_with_head_not_tail(prefs):
        for a in sorted(prefs.keys(), key=str):
            head = head_of(prefs, a)
            tail = tail_of(prefs, a)
            if head and tail and set(head) != set(tail):
                return a
            # If one is empty and the other isn't, also treat as different
            if (bool(head) != bool(tail)):
                return a
        return None

    # Main loop per Phase 2 description
    while True:
        x = first_agent_with_head_not_tail(T)
        if x is None:
            break  # Phase 2 iterations done
        # Build candidates T^{f(x)} and T^{l(x)} by exploring deletions
        T_fx_candidates = []
        T_lx_candidates = []

        head_x = head_of(T, x)[:]
        tail_x = tail_of(T, x)[:]

        # For each z in f_T(x) and w in l_T(z):
        for z in head_x:
            lz = tail_of(T, z)[:]
            for w in lz:
                T_copy = deepcopy(T)
                remove_pair(T_copy, z, w)
                # apply main loop of phase1 to obtain T^{f(x)} (i.e., run phase1_table)
                T_after, infeasible = phase1_table(T_copy)
                if not infeasible:
                    T_fx_candidates.append(T_after)
        # For each y in l_T(x):
        for y in tail_x:
            T_copy = deepcopy(T)
            remove_pair(T_copy, x, y)
            T_after, infeasible = phase1_table(T_copy)
            if not infeasible:
                T_lx_candidates.append(T_after)

        # Choose which branch to set T to according to rules
        if T_fx_candidates:
            # pick the first candidate (deterministic). Could be extended to heuristics.
            T = T_fx_candidates[0]
        elif T_lx_candidates:
            T = T_lx_candidates[0]
        else:
            # neither condition satisfied -> no strongly stable matching exists
            return None, T

    # At this point, construct final assignment graph G (non-bipartite)
    # Nodes: agents with non-empty lists
    agents = [a for a, groups in T.items() if groups]

    # Total order on agents: we will use Python's string ordering of their str() as consistent total order
    # (Callers can use numeric or string agents to control ordering).
    def agent_gt(a, b):
        # return True if a > b under total order (we require edge only if x > y)
        return str(a) > str(b)

    edges_set = set()
    for x in agents:
        head = head_of(T, x)
        for y in head:
            if y in agents and agent_gt(x, y):
                # add undirected edge (min,max) to canonicalize
                e = tuple(sorted([x, y], key=lambda z: str(z)))
                edges_set.add(e)

    # Build graph for matching; attempt to use networkx for general matching (Blossom)
    try:
        import networkx as nx
    except Exception as e:
        raise RuntimeError(
            "Final perfect matching requires general-graph matching (Blossom). "
            "Please install networkx (pip install networkx) and retry. "
            f"Original import error: {e}"
        )

    G = nx.Graph()
    G.add_nodes_from(agents)
    for u, v in edges_set:
        # add edge with weight 1 to use max_weight_matching (unweighted)
        G.add_edge(u, v, weight=1)

    # find maximum matching (returns set of pairs)
    matching_pairs = nx.algorithms.matching.max_weight_matching(G, maxcardinality=True)
    # Convert to dict
    matching_dict = {}
    for u, v in matching_pairs:
        matching_dict[u] = v
        matching_dict[v] = u

    # Check perfectness: every agent must be matched
    if set(matching_dict.keys()) == set(agents) and len(agents) % 2 == 0:
        return matching_dict, T
    else:
        # No perfect matching exists -> no strongly stable matching
        return None, T


# ---------------------------
# Public convenience function
# ---------------------------

def find_strongly_stable_matching(prefs: Dict[Hashable, List[List[Hashable]]]) -> Tuple[
    Optional[Dict[Hashable, Hashable]], Dict[Hashable, List[List[Hashable]]]]:
    """
    High-level function to compute a strongly stable matching for an SRTI instance.

    Parameters
    ----------
    prefs : dict
        Mapping agent -> list of tie-groups (each tie-group is a list of agents).
        Example:
            {
              'a': [['b','c'], ['d']],
              'b': [['a'], ['c']],
              'c': [['b'], ['a']],
              'd': [['a']]
            }

    Returns
    -------
    matching : dict or None
        If a strongly stable matching exists, returns a dict mapping each agent to its match.
        Otherwise returns None.
    final_table : dict
        The preference table after phase transformations (useful for debugging).

    Raises
    ------
    TypeError
        If input preferences are malformed.
    RuntimeError
        If final matching requires a Blossom implementation and networkx is not installed.
    """
    prefs = normalize_preferences(prefs)
    # Run Phase 1 + Phase 2
    matching, final_table = phase2_solve(prefs)
    return matching, final_table


import random


def generate_random_prefs(n, seed=None):
    """生成 n 对匹配者的随机偏好列表"""
    if seed is not None:
        random.seed(seed)

    men = [f"m{i + 1}" for i in range(n)]
    women = [f"w{i + 1}" for i in range(n)]

    men_prefs = {}
    women_prefs = {}

    for m in men:
        men_prefs[m] = random.sample(women, len(women))
    for w in women:
        women_prefs[w] = random.sample(men, len(men))

    return men_prefs, women_prefs


# ---------------------------
# Example usage (commented)
# ---------------------------
# If you want to test the algorithm, supply a small instance:
#
if __name__ == "__main__":
    example_prefs = {
        '1': [['2', '3'], ['4']],
        '2': [['1'], ['3', '4']],
        '3': [['2'], ['1']],
        '4': [['1']]
    }
    example_prefs=generate_random_prefs
    matching, final_table = find_strongly_stable_matching(example_prefs)
    print("Matching:", matching)
    print("Final table:", final_table)
#
# Note: For the final matching this example may or may not produce a perfect matching
# depending on the instance. Install networkx to enable final perfect-matching computation.
